{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf92ddd4-82b6-479c-84e0-5d4631a1fdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "\n",
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38f6362-e983-450d-a922-849a94c9bd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as _glob\n",
    "import pandas as pd\n",
    "import os\n",
    "    \n",
    "def glob(dir, pats, recursive=False):  # faster than match, python3 only\n",
    "    pats = pats if isinstance(pats, (list, tuple)) else [pats]\n",
    "    matches = []\n",
    "    for pat in pats:\n",
    "        matches += _glob.glob(os.path.join(dir, pat), recursive=recursive)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa0efc8c-59e0-42f9-b83a-4451d1a55104",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### load_annotations에서 뒤의 변수 받는거 custom dataset 에서는 이름을 바꿔도 되지만 아래에\n",
    "#### configuration에서는 무조건 변수명을 ann_file로 받아야함\n",
    "@DATASETS.register_module()\n",
    "class Drive_dataset(CustomDataset):\n",
    "    CLASSES=('car','bus','truck', 'special vehicle', 'motorcycle','bicycle','personal mobility','person','Traffic_light', 'Traffic_sign')\n",
    "\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        \n",
    "        CLASSES_dict = {'car' : 0 , 'bus' : 1, 'truck' : 2, 'special vehicle' : 3, 'motorcycle' : 4,'bicycle' : 5 ,'personal mobility' : 6 \n",
    "                        ,'person' : 7 ,'Traffic_light' : 8, 'Traffic_sign' : 9}\n",
    "        \n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        \n",
    "        data_infos = []\n",
    "        \n",
    "        ls = pd.read_csv(ann_file, header = None)\n",
    "        \n",
    "        for idx,an in enumerate(ls.values):\n",
    "            an=an[0]\n",
    "            json_data = {}\n",
    "            with open(an, \"r\") as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "                \n",
    "            ansplit = an.split('/')\n",
    "            \n",
    "            filename = ansplit[0] + '/' + ansplit[1] + '/' + 'images'+'/'+ json_data['image_name']\n",
    "            \n",
    "            width, height = json_data['image_size']\n",
    "\n",
    "            data_info = dict(filename=filename, width=width, height=height)\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "\n",
    "            for ann_data in json_data['Annotation']:\n",
    "                gt_labels.append(CLASSES_dict[ann_data['class_name']])\n",
    "                gt_bboxes.append(ann_data['data'])\n",
    "\n",
    "\n",
    "            data_anno = dict(\n",
    "                    bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                    labels=np.array(gt_labels, dtype=np.long))\n",
    "\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            \n",
    "            data_infos.append(data_info)\n",
    "            \n",
    "            if idx!=0 and idx%20000==0:\n",
    "                print(str(idx)+'/'+str(len(ls))+' load annotations END!')\n",
    "            \n",
    "        \n",
    "        \n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2143d5dc-0af6-42bb-8789-5f29e3d477db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 추가수정 기존 받았던 pretrain과 매칭되는 config로 수정 \n",
    "cfg = Config.fromfile('UniverseNet/configs/waymo_open/universenet50_2008_fp16_4x4_mstrain_640_1280_1x_waymo_open_f0.py') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35439297-236f-4296-a817-f516c8e749e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "pretrained_ckpt = 'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "model = dict(\n",
      "    type='GFL',\n",
      "    backbone=dict(\n",
      "        type='Res2Net',\n",
      "        depth=50,\n",
      "        scales=4,\n",
      "        base_width=26,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        dcn=dict(type='DCN', deform_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, False, False, True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "        )),\n",
      "    neck=[\n",
      "        dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            start_level=1,\n",
      "            add_extra_convs='on_output',\n",
      "            num_outs=5),\n",
      "        dict(\n",
      "            type='SEPC',\n",
      "            out_channels=256,\n",
      "            stacked_convs=4,\n",
      "            pconv_deform=False,\n",
      "            lcconv_deform=True,\n",
      "            ibn=True,\n",
      "            pnorm_eval=False,\n",
      "            lcnorm_eval=False,\n",
      "            lcconv_padding=1)\n",
      "    ],\n",
      "    bbox_head=dict(\n",
      "        type='GFLSEPCHead',\n",
      "        num_classes=3,\n",
      "        in_channels=256,\n",
      "        stacked_convs=0,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            ratios=[1.0],\n",
      "            octave_base_scale=8,\n",
      "            scales_per_octave=1,\n",
      "            strides=[8, 16, 32, 64, 128]),\n",
      "        loss_cls=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0),\n",
      "        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.25),\n",
      "        reg_max=16,\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=2.0)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(type='ATSSAssigner', topk=9),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.6),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'WaymoOpenDataset'\n",
      "data_root = 'data/waymococo_f0/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(960, 640), (1920, 1280)],\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1248, 832),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_train2020.json',\n",
      "        img_prefix='data/waymococo_f0/train2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(960, 640), (1920, 1280)],\n",
      "                multiscale_mode='range',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_val2020.json',\n",
      "        img_prefix='data/waymococo_f0/val2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1248, 832),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_val2020.json',\n",
      "        img_prefix='data/waymococo_f0/val2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1248, 832),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'https://github.com/shinya7y/UniverseNet/releases/download/20.08/universenet50_2008_fp16_4x4_mstrain_480_960_1x_coco_20200812_epoch_12-f522ede5.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "fp16 = dict(loss_scale=512.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c00b1c15-fa7e-4a1e-9317-1764bb932930",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 추가 및 수정 ## \n",
    "cfg.dataset_type  = 'Drive_dataset'\n",
    "cfg.data_root = ''\n",
    "\n",
    "## single GPU 이기 때문에 syncBN 이 아닌 BN으로 수정)\n",
    "cfg.model.backbone.norm_cfg=dict(type='BN', requires_grad=True)\n",
    "\n",
    "## Validation pipeline에 train pipeline 적용하기 위해서 구성 \n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='Resize',\n",
    "        img_scale=(1920, 1200),\n",
    "        multiscale_mode='range',\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomFlip', flip_ratio=0.0),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_rgb=True),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "    \n",
    "]\n",
    "\n",
    "### test pipeline 나중에 test진행에 사용할 거 실제 validation은 위의 pipeline 으로 진행\n",
    "cfg.test_pipeline = [\n",
    "    ### TSET때 사용할 test time augmentation용 pipeline\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1920, 1200),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='Pad', size_divisor=32),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                      dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "]\n",
    "\n",
    "cfg.data=dict(\n",
    "    samples_per_gpu=10,\n",
    "    workers_per_gpu=12,\n",
    "    train=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        ann_file='2DBB/new_train.csv',\n",
    "        pipeline=cfg.train_pipeline),\n",
    "     val=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        ann_file='2DBB/new_valid.csv',\n",
    "        pipeline=cfg.test_pipeline),\n",
    "    test=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        ann_file='2DBB/new_valid.csv',\n",
    "        pipeline=cfg.test_pipeline))\n",
    "\n",
    "cfg.model.bbox_head.num_classes=10\n",
    "\n",
    "cfg.device='cuda'\n",
    "cfg.work_dir = 'checkpoints_ver2'\n",
    "\n",
    "cfg.log_config.interval = 8000 #iteration 단위\n",
    "\n",
    "cfg.seed = 2024\n",
    "\n",
    "set_random_seed(cfg.seed, deterministic=False)\n",
    "\n",
    "cfg.workflow = [('train', 1), ('val',1)]\n",
    "\n",
    "cfg.evaluation = dict(interval=1, metric='mAP')\n",
    "\n",
    "cfg.load_from = 'universenet50_2008_fp16_4x4_mstrain_480_960_2x_coco_20200815_epoch_24-81356447.pth'\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=24)\n",
    "\n",
    "## NMS threshold 파라미터 수정 및 NMS type 수정\n",
    "cfg.model.test_cfg['score_thr']=0.01\n",
    "cfg.model.test_cfg.nms['iou_threshold']=0.3\n",
    "cfg.model.test_cfg.nms['type']='soft_nms'\n",
    "cfg.model.test_cfg.nms['min_score']=0.01\n",
    "cfg.gpu_ids = range(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d599537-f1b0-42c7-8341-78ccc4e5776c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "pretrained_ckpt = 'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "model = dict(\n",
      "    type='GFL',\n",
      "    backbone=dict(\n",
      "        type='Res2Net',\n",
      "        depth=50,\n",
      "        scales=4,\n",
      "        base_width=26,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        dcn=dict(type='DCN', deform_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, False, False, True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "        )),\n",
      "    neck=[\n",
      "        dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            start_level=1,\n",
      "            add_extra_convs='on_output',\n",
      "            num_outs=5),\n",
      "        dict(\n",
      "            type='SEPC',\n",
      "            out_channels=256,\n",
      "            stacked_convs=4,\n",
      "            pconv_deform=False,\n",
      "            lcconv_deform=True,\n",
      "            ibn=True,\n",
      "            pnorm_eval=False,\n",
      "            lcnorm_eval=False,\n",
      "            lcconv_padding=1)\n",
      "    ],\n",
      "    bbox_head=dict(\n",
      "        type='GFLSEPCHead',\n",
      "        num_classes=10,\n",
      "        in_channels=256,\n",
      "        stacked_convs=0,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            ratios=[1.0],\n",
      "            octave_base_scale=8,\n",
      "            scales_per_octave=1,\n",
      "            strides=[8, 16, 32, 64, 128]),\n",
      "        loss_cls=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0),\n",
      "        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.25),\n",
      "        reg_max=16,\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=2.0)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(type='ATSSAssigner', topk=9),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.01,\n",
      "        nms=dict(type='soft_nms', iou_threshold=0.3, min_score=0.01),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'Drive_dataset'\n",
      "data_root = ''\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(1920, 1200),\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1920, 1200),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=10,\n",
      "    workers_per_gpu=12,\n",
      "    train=dict(\n",
      "        type='Drive_dataset',\n",
      "        ann_file='2DBB/new_train.csv',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=(1920, 1200),\n",
      "                multiscale_mode='range',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='Drive_dataset',\n",
      "        ann_file='2DBB/new_valid.csv',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1920, 1200),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='Drive_dataset',\n",
      "        ann_file='2DBB/new_valid.csv',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1920, 1200),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=24)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=8000, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'universenet50_2008_fp16_4x4_mstrain_480_960_2x_coco_20200815_epoch_24-81356447.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1), ('val', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "fp16 = dict(loss_scale=512.0)\n",
      "device = 'cuda'\n",
      "work_dir = 'checkpoints_ver2'\n",
      "seed = 2024\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "931310da-115d-4b5d-b104-8360160b047e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset, build_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef63e39-786a-426f-8dbc-ae4eae084f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:43: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/root/UniverseNet/mmdet/datasets/custom.py:186: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  'CustomDataset does not support filtering empty gt images.')\n"
     ]
    }
   ],
   "source": [
    "test_dataloader_default_args = dict(\n",
    "    samples_per_gpu=1, workers_per_gpu=2, dist=False, shuffle=False)\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "\n",
    "test_loader_cfg = {\n",
    "        **test_dataloader_default_args,\n",
    "        **cfg.data.get('test_dataloader', {})\n",
    "    }\n",
    "# build the dataloader\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(dataset, **test_loader_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f5fe24b-f0a4-4fa9-98b9-8e33a65eb9ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmdet.models import build_detector\n",
    "from mmcv.runner import (get_dist_info, init_dist, load_checkpoint,\n",
    "                         wrap_fp16_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e30509-9af7-4dd1-b96e-5bc00050a91e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/UniverseNet/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: checkpoints_ver2/epoch_24.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-16 06:40:43,708 - root - INFO - DeformConv2dPack backbone.layer4.0.convs.0 is upgraded to version 2.\n",
      "2024-08-16 06:40:43,709 - root - INFO - DeformConv2dPack backbone.layer4.0.convs.1 is upgraded to version 2.\n",
      "2024-08-16 06:40:43,710 - root - INFO - DeformConv2dPack backbone.layer4.0.convs.2 is upgraded to version 2.\n",
      "2024-08-16 06:40:43,712 - root - INFO - DeformConv2dPack backbone.layer4.1.convs.0 is upgraded to version 2.\n",
      "2024-08-16 06:40:43,713 - root - INFO - DeformConv2dPack backbone.layer4.1.convs.1 is upgraded to version 2.\n",
      "2024-08-16 06:40:43,713 - root - INFO - DeformConv2dPack backbone.layer4.1.convs.2 is upgraded to version 2.\n",
      "2024-08-16 06:40:43,715 - root - INFO - DeformConv2dPack backbone.layer4.2.convs.0 is upgraded to version 2.\n",
      "2024-08-16 06:40:43,716 - root - INFO - DeformConv2dPack backbone.layer4.2.convs.1 is upgraded to version 2.\n",
      "2024-08-16 06:40:43,717 - root - INFO - DeformConv2dPack backbone.layer4.2.convs.2 is upgraded to version 2.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'checkpoints_ver2/epoch_24.pth'\n",
    "\n",
    "# build the model and load checkpoint\n",
    "cfg.model.train_cfg = None\n",
    "model = build_detector(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "fp16_cfg = cfg.get('fp16', None)\n",
    "if fp16_cfg is not None:\n",
    "    wrap_fp16_model(model)\n",
    "checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "model.CLASSES = dataset.CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1808aa-e97d-4bb2-91eb-ed21db21ff55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmdet.utils import (build_ddp, build_dp, compat_cfg, get_device,\n",
    "                         replace_cfg_vals, setup_multi_processes,\n",
    "                         update_data_root)\n",
    "\n",
    "from mmdet.apis import single_gpu_test ## 4070 super 단독 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c7cb8f2-6dc9-42fb-bdba-007db4eee2c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                               ] 3/10000, 3.9 task/s, elapsed: 1s, ETA:  2532s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 15.5 task/s, elapsed: 643s, ETA:     0s"
     ]
    }
   ],
   "source": [
    "model = build_dp(model, cfg.device, device_ids=cfg.gpu_ids)\n",
    "outputs = single_gpu_test(model, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a83ccd6-f616-43a4-8abb-b7d816dcc6a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for oss in outputs:\n",
    "#     for o in oss:\n",
    "#         print(len(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d80c224-8d5c-431a-89b4-c458ade2f0dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------iou_thr: 0.5---------------\n",
      "\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32445 | 356040 | 0.975  | 0.940 |\n",
      "| bus               | 952   | 54775  | 0.966  | 0.901 |\n",
      "| truck             | 5896  | 185796 | 0.969  | 0.890 |\n",
      "| special vehicle   | 162   | 32602  | 0.772  | 0.510 |\n",
      "| motorcycle        | 213   | 30697  | 0.864  | 0.751 |\n",
      "| bicycle           | 81    | 10879  | 0.852  | 0.700 |\n",
      "| personal mobility | 45    | 19153  | 0.889  | 0.806 |\n",
      "| person            | 6890  | 115861 | 0.909  | 0.824 |\n",
      "| Traffic_light     | 3932  | 58321  | 0.976  | 0.932 |\n",
      "| Traffic_sign      | 2720  | 122145 | 0.958  | 0.862 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.812 |\n",
      "+-------------------+-------+--------+--------+-------+\n"
     ]
    }
   ],
   "source": [
    "mAP_output = dataset.evaluate(outputs,metric='mAP',iou_thr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e709b98d-9c95-402c-b203-5090c907469a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('AP50', 0.743), ('mAP', 0.7431296110153198)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mAP_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dab6cc01-0992-4996-b8e3-0bbc159d0feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/UniverseNet/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "GFL(\n",
      "  24.288 M, 67.261% Params, 248.673 GFLOPs, 100.000% FLOPs, \n",
      "  (backbone): Res2Net(\n",
      "    20.169 M, 55.856% Params, 202.432 GFLOPs, 81.405% FLOPs, \n",
      "    (stem): Sequential(\n",
      "      0.0 M, 0.000% Params, 16.717 GFLOPs, 6.722% FLOPs, \n",
      "      (0): Conv2d(0.0 M, 0.000% Params, 0.504 GFLOPs, 0.203% FLOPs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(0.0 M, 0.000% Params, 0.019 GFLOPs, 0.008% FLOPs, inplace=True)\n",
      "      (3): Conv2d(0.0 M, 0.000% Params, 5.379 GFLOPs, 2.163% FLOPs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (4): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(0.0 M, 0.000% Params, 0.019 GFLOPs, 0.008% FLOPs, inplace=True)\n",
      "      (6): Conv2d(0.0 M, 0.000% Params, 10.758 GFLOPs, 4.326% FLOPs, 32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (7): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (8): ReLU(0.0 M, 0.000% Params, 0.037 GFLOPs, 0.015% FLOPs, inplace=True)\n",
      "    )\n",
      "    (maxpool): MaxPool2d(0.0 M, 0.000% Params, 0.037 GFLOPs, 0.015% FLOPs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Res2Layer(\n",
      "      0.0 M, 0.000% Params, 30.978 GFLOPs, 12.457% FLOPs, \n",
      "      (0): Bottle2neck(\n",
      "        0.0 M, 0.000% Params, 9.984 GFLOPs, 4.015% FLOPs, \n",
      "        (conv1): Conv2d(0.0 M, 0.000% Params, 0.971 GFLOPs, 0.391% FLOPs, 64, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.0 M, 0.000% Params, 3.885 GFLOPs, 1.562% FLOPs, 104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.064 GFLOPs, 0.026% FLOPs, inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          0.0 M, 0.000% Params, 2.4 GFLOPs, 0.965% FLOPs, \n",
      "          (0): AvgPool2d(0.0 M, 0.000% Params, 0.009 GFLOPs, 0.004% FLOPs, kernel_size=1, stride=1, padding=0)\n",
      "          (1): Conv2d(0.0 M, 0.000% Params, 2.391 GFLOPs, 0.961% FLOPs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (convs): ModuleList(\n",
      "          0.0 M, 0.000% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottle2neck(\n",
      "        0.0 M, 0.000% Params, 10.497 GFLOPs, 4.221% FLOPs, \n",
      "        (conv1): Conv2d(0.0 M, 0.000% Params, 3.885 GFLOPs, 1.562% FLOPs, 256, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.0 M, 0.000% Params, 3.885 GFLOPs, 1.562% FLOPs, 104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.064 GFLOPs, 0.026% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.0 M, 0.000% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Bottle2neck(\n",
      "        0.0 M, 0.000% Params, 10.497 GFLOPs, 4.221% FLOPs, \n",
      "        (conv1): Conv2d(0.0 M, 0.000% Params, 3.885 GFLOPs, 1.562% FLOPs, 256, 104, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.0 M, 0.000% Params, 3.885 GFLOPs, 1.562% FLOPs, 104, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.064 GFLOPs, 0.026% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.0 M, 0.000% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.0 M, 0.000% Params, 0.888 GFLOPs, 0.357% FLOPs, 26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer2): Res2Layer(\n",
      "      1.222 M, 3.384% Params, 50.595 GFLOPs, 20.346% FLOPs, \n",
      "      (0): Bottle2neck(\n",
      "        0.364 M, 1.008% Params, 19.199 GFLOPs, 7.721% FLOPs, \n",
      "        (conv1): Conv2d(0.053 M, 0.147% Params, 7.77 GFLOPs, 3.125% FLOPs, 256, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.106 M, 0.295% Params, 3.885 GFLOPs, 1.562% FLOPs, 208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.055 GFLOPs, 0.022% FLOPs, inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          0.131 M, 0.363% Params, 4.819 GFLOPs, 1.938% FLOPs, \n",
      "          (0): AvgPool2d(0.0 M, 0.000% Params, 0.037 GFLOPs, 0.015% FLOPs, kernel_size=2, stride=2, padding=0)\n",
      "          (1): Conv2d(0.131 M, 0.363% Params, 4.782 GFLOPs, 1.923% FLOPs, 256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (pool): AvgPool2d(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, kernel_size=3, stride=2, padding=1)\n",
      "        (convs): ModuleList(\n",
      "          0.073 M, 0.202% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottle2neck(\n",
      "        0.286 M, 0.792% Params, 10.465 GFLOPs, 4.208% FLOPs, \n",
      "        (conv1): Conv2d(0.106 M, 0.295% Params, 3.885 GFLOPs, 1.562% FLOPs, 512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.106 M, 0.295% Params, 3.885 GFLOPs, 1.562% FLOPs, 208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.032 GFLOPs, 0.013% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.073 M, 0.202% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Bottle2neck(\n",
      "        0.286 M, 0.792% Params, 10.465 GFLOPs, 4.208% FLOPs, \n",
      "        (conv1): Conv2d(0.106 M, 0.295% Params, 3.885 GFLOPs, 1.562% FLOPs, 512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.106 M, 0.295% Params, 3.885 GFLOPs, 1.562% FLOPs, 208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.032 GFLOPs, 0.013% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.073 M, 0.202% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Bottle2neck(\n",
      "        0.286 M, 0.792% Params, 10.465 GFLOPs, 4.208% FLOPs, \n",
      "        (conv1): Conv2d(0.106 M, 0.295% Params, 3.885 GFLOPs, 1.562% FLOPs, 512, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.106 M, 0.295% Params, 3.885 GFLOPs, 1.562% FLOPs, 208, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.032 GFLOPs, 0.013% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.073 M, 0.202% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.024 M, 0.067% Params, 0.888 GFLOPs, 0.357% FLOPs, 52, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer3): Res2Layer(\n",
      "      7.175 M, 19.871% Params, 71.396 GFLOPs, 28.711% FLOPs, \n",
      "      (0): Bottle2neck(\n",
      "        1.455 M, 4.030% Params, 19.15 GFLOPs, 7.701% FLOPs, \n",
      "        (conv1): Conv2d(0.213 M, 0.590% Params, 7.77 GFLOPs, 3.125% FLOPs, 512, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.027 GFLOPs, 0.011% FLOPs, inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          0.524 M, 1.452% Params, 4.8 GFLOPs, 1.930% FLOPs, \n",
      "          (0): AvgPool2d(0.0 M, 0.000% Params, 0.019 GFLOPs, 0.008% FLOPs, kernel_size=2, stride=2, padding=0)\n",
      "          (1): Conv2d(0.524 M, 1.452% Params, 4.782 GFLOPs, 1.923% FLOPs, 512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (pool): AvgPool2d(0.0 M, 0.000% Params, 0.004 GFLOPs, 0.002% FLOPs, kernel_size=3, stride=2, padding=1)\n",
      "        (convs): ModuleList(\n",
      "          0.292 M, 0.809% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottle2neck(\n",
      "        1.144 M, 3.168% Params, 10.449 GFLOPs, 4.202% FLOPs, \n",
      "        (conv1): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.016 GFLOPs, 0.006% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.292 M, 0.809% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Bottle2neck(\n",
      "        1.144 M, 3.168% Params, 10.449 GFLOPs, 4.202% FLOPs, \n",
      "        (conv1): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.016 GFLOPs, 0.006% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.292 M, 0.809% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Bottle2neck(\n",
      "        1.144 M, 3.168% Params, 10.449 GFLOPs, 4.202% FLOPs, \n",
      "        (conv1): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.016 GFLOPs, 0.006% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.292 M, 0.809% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): Bottle2neck(\n",
      "        1.144 M, 3.168% Params, 10.449 GFLOPs, 4.202% FLOPs, \n",
      "        (conv1): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.016 GFLOPs, 0.006% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.292 M, 0.809% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): Bottle2neck(\n",
      "        1.144 M, 3.168% Params, 10.449 GFLOPs, 4.202% FLOPs, \n",
      "        (conv1): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 1024, 416, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(0.426 M, 1.180% Params, 3.885 GFLOPs, 1.562% FLOPs, 416, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.016 GFLOPs, 0.006% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.292 M, 0.809% Params, 2.663 GFLOPs, 1.071% FLOPs, \n",
      "          (0): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (1): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (2): Conv2d(0.097 M, 0.270% Params, 0.888 GFLOPs, 0.357% FLOPs, 104, 104, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layer4): Res2Layer(\n",
      "      11.772 M, 32.602% Params, 32.709 GFLOPs, 13.153% FLOPs, \n",
      "      (0): Bottle2neck(\n",
      "        4.754 M, 13.166% Params, 16.692 GFLOPs, 6.712% FLOPs, \n",
      "        (conv1): Conv2d(0.852 M, 2.359% Params, 7.77 GFLOPs, 3.125% FLOPs, 1024, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1.704 M, 4.719% Params, 3.885 GFLOPs, 1.562% FLOPs, 832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.014 GFLOPs, 0.006% FLOPs, inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          2.097 M, 5.808% Params, 4.791 GFLOPs, 1.927% FLOPs, \n",
      "          (0): AvgPool2d(0.0 M, 0.000% Params, 0.009 GFLOPs, 0.004% FLOPs, kernel_size=2, stride=2, padding=0)\n",
      "          (1): Conv2d(2.097 M, 5.808% Params, 4.782 GFLOPs, 1.923% FLOPs, 1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (pool): AvgPool2d(0.0 M, 0.000% Params, 0.002 GFLOPs, 0.001% FLOPs, kernel_size=3, stride=2, padding=1)\n",
      "        (convs): ModuleList(\n",
      "          0.101 M, 0.280% Params, 0.231 GFLOPs, 0.093% FLOPs, \n",
      "          (0): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(2, 2),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "          (1): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(2, 2),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "          (2): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(2, 2),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottle2neck(\n",
      "        3.509 M, 9.718% Params, 8.009 GFLOPs, 3.221% FLOPs, \n",
      "        (conv1): Conv2d(1.704 M, 4.719% Params, 3.885 GFLOPs, 1.562% FLOPs, 2048, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1.704 M, 4.719% Params, 3.885 GFLOPs, 1.562% FLOPs, 832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.101 M, 0.280% Params, 0.231 GFLOPs, 0.093% FLOPs, \n",
      "          (0): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "          (1): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "          (2): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Bottle2neck(\n",
      "        3.509 M, 9.718% Params, 8.009 GFLOPs, 3.221% FLOPs, \n",
      "        (conv1): Conv2d(1.704 M, 4.719% Params, 3.885 GFLOPs, 1.562% FLOPs, 2048, 832, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1.704 M, 4.719% Params, 3.885 GFLOPs, 1.562% FLOPs, 832, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(0.0 M, 0.000% Params, 0.008 GFLOPs, 0.003% FLOPs, inplace=True)\n",
      "        (convs): ModuleList(\n",
      "          0.101 M, 0.280% Params, 0.231 GFLOPs, 0.093% FLOPs, \n",
      "          (0): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "          (1): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "          (2): DeformConv2dPack(in_channels=208,\n",
      "          out_channels=208,\n",
      "          kernel_size=(3, 3),\n",
      "          stride=(1, 1),\n",
      "          padding=(1, 1),\n",
      "          dilation=(1, 1),\n",
      "          groups=1,\n",
      "          deform_groups=1,\n",
      "          bias=False)\n",
      "        )\n",
      "        (bns): ModuleList(\n",
      "          0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "          (0): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (1): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): SyncBatchNorm(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, 208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  init_cfg={'type': 'Pretrained', 'checkpoint': 'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'}\n",
      "  (neck): Sequential(\n",
      "    3.955 M, 10.952% Params, 38.287 GFLOPs, 15.397% FLOPs, \n",
      "    (0): FPN(\n",
      "      3.869 M, 10.714% Params, 37.058 GFLOPs, 14.902% FLOPs, \n",
      "      (lateral_convs): ModuleList(\n",
      "        0.918 M, 2.543% Params, 8.38 GFLOPs, 3.370% FLOPs, \n",
      "        (0): ConvModule(\n",
      "          0.131 M, 0.364% Params, 4.791 GFLOPs, 1.927% FLOPs, \n",
      "          (conv): Conv2d(0.131 M, 0.364% Params, 4.791 GFLOPs, 1.927% FLOPs, 512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ConvModule(\n",
      "          0.262 M, 0.727% Params, 2.393 GFLOPs, 0.962% FLOPs, \n",
      "          (conv): Conv2d(0.262 M, 0.727% Params, 2.393 GFLOPs, 0.962% FLOPs, 1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ConvModule(\n",
      "          0.525 M, 1.453% Params, 1.196 GFLOPs, 0.481% FLOPs, \n",
      "          (conv): Conv2d(0.525 M, 1.453% Params, 1.196 GFLOPs, 0.481% FLOPs, 2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (fpn_convs): ModuleList(\n",
      "        2.95 M, 8.171% Params, 28.678 GFLOPs, 11.532% FLOPs, \n",
      "        (0): ConvModule(\n",
      "          0.59 M, 1.634% Params, 21.526 GFLOPs, 8.656% FLOPs, \n",
      "          (conv): Conv2d(0.59 M, 1.634% Params, 21.526 GFLOPs, 8.656% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (1): ConvModule(\n",
      "          0.59 M, 1.634% Params, 5.382 GFLOPs, 2.164% FLOPs, \n",
      "          (conv): Conv2d(0.59 M, 1.634% Params, 5.382 GFLOPs, 2.164% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (2): ConvModule(\n",
      "          0.59 M, 1.634% Params, 1.345 GFLOPs, 0.541% FLOPs, \n",
      "          (conv): Conv2d(0.59 M, 1.634% Params, 1.345 GFLOPs, 0.541% FLOPs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (3): ConvModule(\n",
      "          0.59 M, 1.634% Params, 0.336 GFLOPs, 0.135% FLOPs, \n",
      "          (conv): Conv2d(0.59 M, 1.634% Params, 0.336 GFLOPs, 0.135% FLOPs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "        (4): ConvModule(\n",
      "          0.59 M, 1.634% Params, 0.089 GFLOPs, 0.036% FLOPs, \n",
      "          (conv): Conv2d(0.59 M, 1.634% Params, 0.089 GFLOPs, 0.036% FLOPs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "    (1): SEPC(\n",
      "      0.086 M, 0.238% Params, 1.23 GFLOPs, 0.494% FLOPs, \n",
      "      (pconvs): ModuleList(\n",
      "        0.002 M, 0.006% Params, 0.149 GFLOPs, 0.060% FLOPs, \n",
      "        (0): PConvModule(\n",
      "          0.001 M, 0.001% Params, 0.037 GFLOPs, 0.015% FLOPs, \n",
      "          (pconv): ModuleList(\n",
      "            0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "            (0): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (1): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (2): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(2, 2),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "          )\n",
      "          (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.025 GFLOPs, 0.010% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(0.0 M, 0.000% Params, 0.012 GFLOPs, 0.005% FLOPs, )\n",
      "        )\n",
      "        (1): PConvModule(\n",
      "          0.001 M, 0.001% Params, 0.037 GFLOPs, 0.015% FLOPs, \n",
      "          (pconv): ModuleList(\n",
      "            0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "            (0): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (1): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (2): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(2, 2),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "          )\n",
      "          (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.025 GFLOPs, 0.010% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(0.0 M, 0.000% Params, 0.012 GFLOPs, 0.005% FLOPs, )\n",
      "        )\n",
      "        (2): PConvModule(\n",
      "          0.001 M, 0.001% Params, 0.037 GFLOPs, 0.015% FLOPs, \n",
      "          (pconv): ModuleList(\n",
      "            0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "            (0): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (1): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (2): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(2, 2),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "          )\n",
      "          (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.025 GFLOPs, 0.010% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(0.0 M, 0.000% Params, 0.012 GFLOPs, 0.005% FLOPs, )\n",
      "        )\n",
      "        (3): PConvModule(\n",
      "          0.001 M, 0.001% Params, 0.037 GFLOPs, 0.015% FLOPs, \n",
      "          (pconv): ModuleList(\n",
      "            0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "            (0): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (1): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(1, 1),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "            (2): SEPCConv(in_channels=256,\n",
      "            out_channels=256,\n",
      "            kernel_size=(3, 3),\n",
      "            stride=(2, 2),\n",
      "            padding=(1, 1),\n",
      "            dilation=(1, 1),\n",
      "            groups=1,\n",
      "            deform_groups=1,\n",
      "            bias=False)\n",
      "          )\n",
      "          (bn): BatchNorm2d(0.001 M, 0.001% Params, 0.025 GFLOPs, 0.010% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (relu): ReLU(0.0 M, 0.000% Params, 0.012 GFLOPs, 0.005% FLOPs, )\n",
      "        )\n",
      "      )\n",
      "      (lconv): SEPCConv(in_channels=256,\n",
      "      out_channels=256,\n",
      "      kernel_size=(3, 3),\n",
      "      stride=(1, 1),\n",
      "      padding=(1, 1),\n",
      "      dilation=(1, 1),\n",
      "      groups=1,\n",
      "      deform_groups=1,\n",
      "      bias=False)\n",
      "      (cconv): SEPCConv(in_channels=256,\n",
      "      out_channels=256,\n",
      "      kernel_size=(3, 3),\n",
      "      stride=(1, 1),\n",
      "      padding=(1, 1),\n",
      "      dilation=(1, 1),\n",
      "      groups=1,\n",
      "      deform_groups=1,\n",
      "      bias=False)\n",
      "      (bn_loc): BatchNorm2d(0.001 M, 0.001% Params, 0.025 GFLOPs, 0.010% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn_cls): BatchNorm2d(0.001 M, 0.001% Params, 0.025 GFLOPs, 0.010% FLOPs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(0.0 M, 0.000% Params, 0.025 GFLOPs, 0.010% FLOPs, )\n",
      "    )\n",
      "  )\n",
      "  (bbox_head): GFLSEPCHead(\n",
      "    0.164 M, 0.453% Params, 7.954 GFLOPs, 3.198% FLOPs, \n",
      "    (loss_cls): QualityFocalLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "    (loss_bbox): GIoULoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "    (relu): ReLU(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, inplace=True)\n",
      "    (cls_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "    (reg_convs): ModuleList(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "    (gfl_cls): Conv2d(0.007 M, 0.019% Params, 0.336 GFLOPs, 0.135% FLOPs, 256, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (gfl_reg): Conv2d(0.157 M, 0.434% Params, 7.618 GFLOPs, 3.063% FLOPs, 256, 68, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (scales): ModuleList(\n",
      "      0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, \n",
      "      (0): Scale(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "      (1): Scale(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "      (2): Scale(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "      (3): Scale(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "      (4): Scale(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "    )\n",
      "    (integral): Integral(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "    (loss_dfl): DistributionFocalLoss(0.0 M, 0.000% Params, 0.0 GFLOPs, 0.000% FLOPs, )\n",
      "  )\n",
      "  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'gfl_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
      ")\n",
      "==============================\n",
      "Use size divisor set input shape from (3, 1920, 1200) to (3, 1920, 1216)\n",
      "\n",
      "==============================\n",
      "Input shape: (3, 1920, 1216)\n",
      "Flops: 248.67 GFLOPs\n",
      "Params: 36.11 M\n",
      "==============================\n",
      "!!!Please be cautious if you use the results in papers. You may need to check if all ops are supported and verify that the flops computation is correct.\n"
     ]
    }
   ],
   "source": [
    "!python UniverseNet/tools/analysis_tools/get_flops.py  UniverseNet/configs/waymo_open/universenet50_2008_fp16_4x4_mstrain_640_1280_1x_waymo_open_f0.py --shape  1920 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0af18-fe86-4e42-a559-daf36ff04629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
