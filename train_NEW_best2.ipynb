{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87230121-40b1-48c5-8ca7-c928ca6a7b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "\n",
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39d4ea6-a43d-4141-9fe3-3d56b35aa0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob as _glob\n",
    "import os\n",
    "    \n",
    "def glob(dir, pats, recursive=False):  # faster than match, python3 only\n",
    "    pats = pats if isinstance(pats, (list, tuple)) else [pats]\n",
    "    matches = []\n",
    "    for pat in pats:\n",
    "        matches += _glob.glob(os.path.join(dir, pat), recursive=recursive)\n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54147c9a-eb58-429a-a5cc-2fbc0c42848d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### load_annotations에서 뒤의 변수 받는거 custom dataset 에서는 이름을 바꿔도 되지만 아래에\n",
    "#### configuration에서는 무조건 변수명을 ann_file로 받아야함\n",
    "@DATASETS.register_module()\n",
    "class Drive_dataset(CustomDataset):\n",
    "    CLASSES=('car','bus','truck', 'special vehicle', 'motorcycle','bicycle','personal mobility','person','Traffic_light', 'Traffic_sign')\n",
    "\n",
    "\n",
    "    def load_annotations(self, ann_fol):\n",
    "        \n",
    "        CLASSES_dict = {'car' : 0 , 'bus' : 1, 'truck' : 2, 'special vehicle' : 3, 'motorcycle' : 4,'bicycle' : 5 ,'personal mobility' : 6 \n",
    "                        ,'person' : 7 ,'Traffic_light' : 8, 'Traffic_sign' : 9}\n",
    "        \n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        \n",
    "        data_infos = []\n",
    "        \n",
    "        ls = glob(ann_fol,'*',True)\n",
    "        \n",
    "        for idx,an in enumerate(ls):\n",
    "            json_data = {}\n",
    "            with open(an, \"r\") as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "                \n",
    "            ansplit = an.split('/')\n",
    "            \n",
    "            filename = ansplit[0] + '/' + ansplit[1] + '/' + 'images'+'/'+ json_data['image_name']\n",
    "            \n",
    "            width, height = json_data['image_size']\n",
    "\n",
    "            data_info = dict(filename=filename, width=width, height=height)\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "\n",
    "            for ann_data in json_data['Annotation']:\n",
    "                gt_labels.append(CLASSES_dict[ann_data['class_name']])\n",
    "                gt_bboxes.append(ann_data['data'])\n",
    "\n",
    "\n",
    "            data_anno = dict(\n",
    "                    bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                    labels=np.array(gt_labels, dtype=np.long))\n",
    "\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "            \n",
    "            if idx!=0 and idx%20000==0:\n",
    "                print(str(idx)+'/'+str(len(ls))+' load annotations END!')\n",
    "            \n",
    "        \n",
    "        \n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "401441c5-94c4-4c5a-b7a0-0372ac2bdd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 추가수정 기존 받았던 pretrain과 매칭되는 config로 수정 \n",
    "cfg = Config.fromfile('UniverseNet/configs/waymo_open/universenet50_2008_fp16_4x4_mstrain_640_1280_1x_waymo_open_f0.py') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5790f2d-9a8c-4549-bd09-dafd6623f6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "pretrained_ckpt = 'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "model = dict(\n",
      "    type='GFL',\n",
      "    backbone=dict(\n",
      "        type='Res2Net',\n",
      "        depth=50,\n",
      "        scales=4,\n",
      "        base_width=26,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        dcn=dict(type='DCN', deform_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, False, False, True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "        )),\n",
      "    neck=[\n",
      "        dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            start_level=1,\n",
      "            add_extra_convs='on_output',\n",
      "            num_outs=5),\n",
      "        dict(\n",
      "            type='SEPC',\n",
      "            out_channels=256,\n",
      "            stacked_convs=4,\n",
      "            pconv_deform=False,\n",
      "            lcconv_deform=True,\n",
      "            ibn=True,\n",
      "            pnorm_eval=False,\n",
      "            lcnorm_eval=False,\n",
      "            lcconv_padding=1)\n",
      "    ],\n",
      "    bbox_head=dict(\n",
      "        type='GFLSEPCHead',\n",
      "        num_classes=3,\n",
      "        in_channels=256,\n",
      "        stacked_convs=0,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            ratios=[1.0],\n",
      "            octave_base_scale=8,\n",
      "            scales_per_octave=1,\n",
      "            strides=[8, 16, 32, 64, 128]),\n",
      "        loss_cls=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0),\n",
      "        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.25),\n",
      "        reg_max=16,\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=2.0)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(type='ATSSAssigner', topk=9),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.6),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'WaymoOpenDataset'\n",
      "data_root = 'data/waymococo_f0/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(960, 640), (1920, 1280)],\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1248, 832),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_train2020.json',\n",
      "        img_prefix='data/waymococo_f0/train2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(960, 640), (1920, 1280)],\n",
      "                multiscale_mode='range',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_val2020.json',\n",
      "        img_prefix='data/waymococo_f0/val2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1248, 832),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_val2020.json',\n",
      "        img_prefix='data/waymococo_f0/val2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1248, 832),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'https://github.com/shinya7y/UniverseNet/releases/download/20.08/universenet50_2008_fp16_4x4_mstrain_480_960_1x_coco_20200812_epoch_12-f522ede5.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "fp16 = dict(loss_scale=512.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3734d92-49a0-4456-9110-a88b1081cc47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 추가 및 수정 ## \n",
    "cfg.dataset_type  = 'Drive_dataset'\n",
    "cfg.data_root = ''\n",
    "\n",
    "## single GPU 이기 때문에 syncBN 이 아닌 BN으로 수정)\n",
    "cfg.model.backbone.norm_cfg=dict(type='BN', requires_grad=True)\n",
    "\n",
    "## Validation pipeline에 train pipeline 적용하기 위해서 구성 \n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='Resize',\n",
    "        img_scale=(1920, 1200),\n",
    "        multiscale_mode='range',\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomFlip', flip_ratio=0.0),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_rgb=True),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "    \n",
    "]\n",
    "\n",
    "### test pipeline 나중에 test진행에 사용할 거 실제 validation은 위의 pipeline 으로 진행\n",
    "cfg.test_pipeline = [\n",
    "    ### TSET때 사용할 test time augmentation용 pipeline\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1920, 1200),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='Pad', size_divisor=32),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                      dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data=dict(\n",
    "    samples_per_gpu=10, # batchsize\n",
    "    workers_per_gpu=12, # batch를 불러오기 위한 작업 thread 갯수 \n",
    "    # train dataset \n",
    "    train=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        ann_file='2DBB/training/labels/',\n",
    "        pipeline=cfg.train_pipeline),\n",
    "    # validation dataset  \n",
    "    val=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        ann_file='2DBB/validation/labels',\n",
    "        pipeline=cfg.test_pipeline),\n",
    "    test=None)\n",
    "\n",
    "## class 갯수 \n",
    "cfg.model.bbox_head.num_classes=10\n",
    "\n",
    "## GPU 학습 진행을 위한 device 선언\n",
    "cfg.device='cuda'\n",
    "\n",
    "## weight 와 학습 log 저장 위치 \n",
    "cfg.work_dir = 'checkpoints_Best_ver2'\n",
    "\n",
    "## log interval\n",
    "cfg.log_config.interval = 8000 #iteration 단위\n",
    "\n",
    "cfg.seed = 2024\n",
    "\n",
    "## seed 고정 진행\n",
    "set_random_seed(cfg.seed, deterministic=False)\n",
    "\n",
    "cfg.workflow = [('train', 1), ('val',1)]\n",
    "\n",
    "cfg.evaluation = dict(interval=1, metric='mAP')\n",
    "\n",
    "### coco dataset으로 pretrain된 weight load 할 path\n",
    "cfg.load_from = 'universenet50_2008_fp16_4x4_mstrain_480_960_2x_coco_20200815_epoch_24-81356447.pth'\n",
    "\n",
    "### epoch 선언\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=50)\n",
    "\n",
    "### 사용할 GPU 선언\n",
    "cfg.gpu_ids = range(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e9fb850-1505-48c2-9948-8fe00a48f53a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "pretrained_ckpt = 'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "model = dict(\n",
      "    type='GFL',\n",
      "    backbone=dict(\n",
      "        type='Res2Net',\n",
      "        depth=50,\n",
      "        scales=4,\n",
      "        base_width=26,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        dcn=dict(type='DCN', deform_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, False, False, True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "        )),\n",
      "    neck=[\n",
      "        dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            start_level=1,\n",
      "            add_extra_convs='on_output',\n",
      "            num_outs=5),\n",
      "        dict(\n",
      "            type='SEPC',\n",
      "            out_channels=256,\n",
      "            stacked_convs=4,\n",
      "            pconv_deform=False,\n",
      "            lcconv_deform=True,\n",
      "            ibn=True,\n",
      "            pnorm_eval=False,\n",
      "            lcnorm_eval=False,\n",
      "            lcconv_padding=1)\n",
      "    ],\n",
      "    bbox_head=dict(\n",
      "        type='GFLSEPCHead',\n",
      "        num_classes=10,\n",
      "        in_channels=256,\n",
      "        stacked_convs=0,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            ratios=[1.0],\n",
      "            octave_base_scale=8,\n",
      "            scales_per_octave=1,\n",
      "            strides=[8, 16, 32, 64, 128]),\n",
      "        loss_cls=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0),\n",
      "        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.25),\n",
      "        reg_max=16,\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=2.0)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(type='ATSSAssigner', topk=9),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.6),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'Drive_dataset'\n",
      "data_root = ''\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(1920, 1200),\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1920, 1200),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=10,\n",
      "    workers_per_gpu=12,\n",
      "    train=dict(\n",
      "        type='Drive_dataset',\n",
      "        ann_file='2DBB/training/labels/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=(1920, 1200),\n",
      "                multiscale_mode='range',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='Drive_dataset',\n",
      "        ann_file='2DBB/validation/labels',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1920, 1200),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=None)\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=50)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=8000, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'universenet50_2008_fp16_4x4_mstrain_480_960_2x_coco_20200815_epoch_24-81356447.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1), ('val', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "fp16 = dict(loss_scale=512.0)\n",
      "device = 'cuda'\n",
      "work_dir = 'checkpoints_Best_ver2'\n",
      "seed = 2024\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dccf7fd7-46b3-4307-8772-844cf0079500",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "import torch\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c6f8d79-bfec-43a6-9ba0-a0b86b6e1116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:42: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/root/UniverseNet/mmdet/datasets/custom.py:186: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  'CustomDataset does not support filtering empty gt images.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/80000 load annotations END!\n",
      "40000/80000 load annotations END!\n",
      "60000/80000 load annotations END!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 12:36:24,471 - mmdet - INFO - image shape: height=320, width=480 in Mosaic.__init__\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/UniverseNet/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "2024-08-14 12:36:25,326 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2024-08-14 12:36:26,977 - mmdet - INFO - load checkpoint from local path: universenet50_2008_fp16_4x4_mstrain_480_960_2x_coco_20200815_epoch_24-81356447.pth\n",
      "2024-08-14 12:36:27,049 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for bbox_head.gfl_cls.weight: copying a param with shape torch.Size([80, 256, 3, 3]) from checkpoint, the shape in current model is torch.Size([10, 256, 3, 3]).\n",
      "size mismatch for bbox_head.gfl_cls.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([10]).\n",
      "2024-08-14 12:36:27,050 - mmdet - INFO - Start running, host: root@de6c290dc761, work_dir: /root/checkpoints_Best_ver2\n",
      "2024-08-14 12:36:27,051 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(ABOVE_NORMAL) Fp16OptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) Fp16OptimizerHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2024-08-14 12:36:27,051 - mmdet - INFO - workflow: [('train', 1), ('val', 1)], max: 50 epochs\n",
      "2024-08-14 12:36:27,052 - mmdet - INFO - Checkpoints will be saved to /root/checkpoints_Best_ver2 by HardDiskBackend.\n",
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "2024-08-14 13:39:56,032 - mmdet - INFO - Epoch [1][8000/9521]\tlr: 1.000e-02, eta: 2 days, 13:53:30, time: 0.476, data_time: 0.013, memory: 6002, loss_cls: 0.2629, loss_bbox: 0.3100, loss_dfl: 0.1708, loss: 0.7437\n",
      "2024-08-14 13:52:00,231 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 15.4 task/s, elapsed: 648s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 14:03:30,792 - mmdet - INFO - \n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32964 | 296290 | 0.884  | 0.696 |\n",
      "| bus               | 979   | 34646  | 0.637  | 0.373 |\n",
      "| truck             | 5874  | 147325 | 0.798  | 0.514 |\n",
      "| special vehicle   | 202   | 13160  | 0.337  | 0.066 |\n",
      "| motorcycle        | 235   | 5536   | 0.455  | 0.208 |\n",
      "| bicycle           | 62    | 2073   | 0.387  | 0.203 |\n",
      "| personal mobility | 43    | 6902   | 0.651  | 0.128 |\n",
      "| person            | 7347  | 142852 | 0.797  | 0.559 |\n",
      "| Traffic_light     | 3298  | 92718  | 0.870  | 0.465 |\n",
      "| Traffic_sign      | 2889  | 162428 | 0.869  | 0.653 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.386 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "2024-08-14 14:03:31,071 - mmdet - INFO - Epoch(val) [1][10000]\tAP50: 0.3860, mAP: 0.3865\n",
      "2024-08-14 14:14:59,570 - mmdet - INFO - Epoch(val) [1][1000]\tloss_cls: 0.4909, loss_bbox: 0.2963, loss_dfl: 0.2063, loss: 0.9935\n",
      "2024-08-14 15:18:24,286 - mmdet - INFO - Epoch [2][8000/9521]\tlr: 1.000e-02, eta: 2 days, 7:20:03, time: 0.475, data_time: 0.014, memory: 6002, loss_cls: 0.1120, loss_bbox: 0.2571, loss_dfl: 0.1581, loss: 0.5272\n",
      "2024-08-14 15:30:34,346 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 15.3 task/s, elapsed: 655s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 15:42:01,970 - mmdet - INFO - \n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32964 | 376682 | 0.907  | 0.733 |\n",
      "| bus               | 979   | 25865  | 0.623  | 0.392 |\n",
      "| truck             | 5874  | 195182 | 0.811  | 0.522 |\n",
      "| special vehicle   | 202   | 11232  | 0.272  | 0.078 |\n",
      "| motorcycle        | 235   | 7639   | 0.468  | 0.209 |\n",
      "| bicycle           | 62    | 1364   | 0.306  | 0.125 |\n",
      "| personal mobility | 43    | 4626   | 0.558  | 0.179 |\n",
      "| person            | 7347  | 93827  | 0.754  | 0.531 |\n",
      "| Traffic_light     | 3298  | 46465  | 0.767  | 0.448 |\n",
      "| Traffic_sign      | 2889  | 78465  | 0.804  | 0.587 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.380 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "2024-08-14 15:42:02,288 - mmdet - INFO - Epoch(val) [2][10000]\tAP50: 0.3800, mAP: 0.3803\n",
      "2024-08-14 15:53:30,381 - mmdet - INFO - Epoch(val) [2][1000]\tloss_cls: 0.4645, loss_bbox: 0.3076, loss_dfl: 0.2130, loss: 0.9851\n",
      "2024-08-14 16:57:02,911 - mmdet - INFO - Epoch [3][8000/9521]\tlr: 1.000e-02, eta: 2 days, 4:41:09, time: 0.476, data_time: 0.014, memory: 6002, loss_cls: 0.1002, loss_bbox: 0.2390, loss_dfl: 0.1539, loss: 0.4931\n",
      "2024-08-14 17:09:09,806 - mmdet - INFO - Saving checkpoint at 3 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 15.1 task/s, elapsed: 663s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 17:20:49,532 - mmdet - INFO - \n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32964 | 331445 | 0.858  | 0.620 |\n",
      "| bus               | 979   | 23690  | 0.640  | 0.406 |\n",
      "| truck             | 5874  | 160936 | 0.804  | 0.506 |\n",
      "| special vehicle   | 202   | 12392  | 0.312  | 0.068 |\n",
      "| motorcycle        | 235   | 6474   | 0.481  | 0.276 |\n",
      "| bicycle           | 62    | 1939   | 0.387  | 0.200 |\n",
      "| personal mobility | 43    | 4210   | 0.512  | 0.077 |\n",
      "| person            | 7347  | 67612  | 0.719  | 0.527 |\n",
      "| Traffic_light     | 3298  | 37435  | 0.775  | 0.451 |\n",
      "| Traffic_sign      | 2889  | 47584  | 0.799  | 0.634 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.376 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "2024-08-14 17:20:49,545 - mmdet - INFO - Epoch(val) [3][10000]\tAP50: 0.3760, mAP: 0.3765\n",
      "2024-08-14 17:32:15,629 - mmdet - INFO - Epoch(val) [3][1000]\tloss_cls: 0.5638, loss_bbox: 0.3020, loss_dfl: 0.2120, loss: 1.0778\n",
      "2024-08-14 18:35:48,927 - mmdet - INFO - Epoch [4][8000/9521]\tlr: 1.000e-02, eta: 2 days, 2:51:57, time: 0.476, data_time: 0.014, memory: 6002, loss_cls: 0.0939, loss_bbox: 0.2281, loss_dfl: 0.1514, loss: 0.4734\n",
      "2024-08-14 18:48:02,818 - mmdet - INFO - Saving checkpoint at 4 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 15.1 task/s, elapsed: 663s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 18:59:45,345 - mmdet - INFO - \n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32964 | 456109 | 0.833  | 0.638 |\n",
      "| bus               | 979   | 17287  | 0.605  | 0.350 |\n",
      "| truck             | 5874  | 198194 | 0.784  | 0.484 |\n",
      "| special vehicle   | 202   | 11621  | 0.213  | 0.030 |\n",
      "| motorcycle        | 235   | 3999   | 0.302  | 0.177 |\n",
      "| bicycle           | 62    | 1260   | 0.161  | 0.101 |\n",
      "| personal mobility | 43    | 3757   | 0.372  | 0.051 |\n",
      "| person            | 7347  | 43845  | 0.613  | 0.431 |\n",
      "| Traffic_light     | 3298  | 48193  | 0.743  | 0.464 |\n",
      "| Traffic_sign      | 2889  | 97578  | 0.798  | 0.606 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.333 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "2024-08-14 18:59:45,682 - mmdet - INFO - Epoch(val) [4][10000]\tAP50: 0.3330, mAP: 0.3332\n",
      "2024-08-14 19:11:12,117 - mmdet - INFO - Epoch(val) [4][1000]\tloss_cls: 0.5631, loss_bbox: 0.3104, loss_dfl: 0.2170, loss: 1.0905\n",
      "2024-08-14 20:14:46,816 - mmdet - INFO - Epoch [5][8000/9521]\tlr: 1.000e-02, eta: 2 days, 1:21:50, time: 0.477, data_time: 0.014, memory: 6002, loss_cls: 0.0890, loss_bbox: 0.2199, loss_dfl: 0.1497, loss: 0.4586\n",
      "2024-08-14 20:27:01,639 - mmdet - INFO - Saving checkpoint at 5 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 14.9 task/s, elapsed: 673s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 20:38:54,708 - mmdet - INFO - \n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32964 | 483135 | 0.811  | 0.609 |\n",
      "| bus               | 979   | 25390  | 0.534  | 0.251 |\n",
      "| truck             | 5874  | 142998 | 0.724  | 0.435 |\n",
      "| special vehicle   | 202   | 15959  | 0.198  | 0.030 |\n",
      "| motorcycle        | 235   | 3406   | 0.260  | 0.126 |\n",
      "| bicycle           | 62    | 933    | 0.177  | 0.107 |\n",
      "| personal mobility | 43    | 2195   | 0.302  | 0.036 |\n",
      "| person            | 7347  | 112949 | 0.672  | 0.454 |\n",
      "| Traffic_light     | 3298  | 35711  | 0.741  | 0.434 |\n",
      "| Traffic_sign      | 2889  | 45379  | 0.739  | 0.587 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.307 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "2024-08-14 20:38:54,721 - mmdet - INFO - Epoch(val) [5][10000]\tAP50: 0.3070, mAP: 0.3069\n",
      "2024-08-14 20:50:24,659 - mmdet - INFO - Epoch(val) [5][1000]\tloss_cls: 0.5429, loss_bbox: 0.3261, loss_dfl: 0.2225, loss: 1.0916\n",
      "2024-08-14 21:54:00,633 - mmdet - INFO - Epoch [6][8000/9521]\tlr: 1.000e-02, eta: 2 days, 0:00:57, time: 0.477, data_time: 0.015, memory: 6002, loss_cls: 0.0858, loss_bbox: 0.2138, loss_dfl: 0.1483, loss: 0.4479\n",
      "2024-08-14 22:06:12,431 - mmdet - INFO - Saving checkpoint at 6 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 14.9 task/s, elapsed: 671s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 22:18:00,511 - mmdet - INFO - \n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32964 | 216749 | 0.763  | 0.580 |\n",
      "| bus               | 979   | 27217  | 0.520  | 0.289 |\n",
      "| truck             | 5874  | 176109 | 0.732  | 0.418 |\n",
      "| special vehicle   | 202   | 8837   | 0.104  | 0.014 |\n",
      "| motorcycle        | 235   | 3268   | 0.204  | 0.103 |\n",
      "| bicycle           | 62    | 1493   | 0.210  | 0.066 |\n",
      "| personal mobility | 43    | 3175   | 0.163  | 0.024 |\n",
      "| person            | 7347  | 47067  | 0.592  | 0.384 |\n",
      "| Traffic_light     | 3298  | 39011  | 0.700  | 0.384 |\n",
      "| Traffic_sign      | 2889  | 83505  | 0.772  | 0.601 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.286 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "2024-08-14 22:18:00,850 - mmdet - INFO - Epoch(val) [6][10000]\tAP50: 0.2860, mAP: 0.2863\n",
      "2024-08-14 22:29:29,611 - mmdet - INFO - Epoch(val) [6][1000]\tloss_cls: 0.6162, loss_bbox: 0.3054, loss_dfl: 0.2156, loss: 1.1372\n",
      "2024-08-14 23:33:02,985 - mmdet - INFO - Epoch [7][8000/9521]\tlr: 1.000e-02, eta: 1 day, 22:44:49, time: 0.476, data_time: 0.014, memory: 6002, loss_cls: 0.0827, loss_bbox: 0.2087, loss_dfl: 0.1472, loss: 0.4386\n",
      "2024-08-14 23:45:17,857 - mmdet - INFO - Saving checkpoint at 7 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 14.7 task/s, elapsed: 680s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-14 23:57:13,795 - mmdet - INFO - \n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32964 | 346813 | 0.781  | 0.561 |\n",
      "| bus               | 979   | 17418  | 0.464  | 0.233 |\n",
      "| truck             | 5874  | 179425 | 0.697  | 0.396 |\n",
      "| special vehicle   | 202   | 12626  | 0.099  | 0.006 |\n",
      "| motorcycle        | 235   | 4970   | 0.200  | 0.055 |\n",
      "| bicycle           | 62    | 1452   | 0.161  | 0.005 |\n",
      "| personal mobility | 43    | 3409   | 0.233  | 0.025 |\n",
      "| person            | 7347  | 97756  | 0.611  | 0.379 |\n",
      "| Traffic_light     | 3298  | 39164  | 0.654  | 0.408 |\n",
      "| Traffic_sign      | 2889  | 45849  | 0.716  | 0.535 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.260 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "2024-08-14 23:57:13,801 - mmdet - INFO - Epoch(val) [7][10000]\tAP50: 0.2600, mAP: 0.2603\n",
      "2024-08-15 00:08:41,710 - mmdet - INFO - Epoch(val) [7][1000]\tloss_cls: 0.6519, loss_bbox: 0.3173, loss_dfl: 0.2201, loss: 1.1894\n",
      "2024-08-15 01:12:17,635 - mmdet - INFO - Epoch [8][8000/9521]\tlr: 1.000e-02, eta: 1 day, 21:32:11, time: 0.477, data_time: 0.015, memory: 6002, loss_cls: 0.0805, loss_bbox: 0.2047, loss_dfl: 0.1464, loss: 0.4315\n",
      "2024-08-15 01:24:29,276 - mmdet - INFO - Saving checkpoint at 8 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>] 10000/10000, 14.8 task/s, elapsed: 676s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-15 01:36:16,754 - mmdet - INFO - \n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| class             | gts   | dets   | recall | ap    |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| car               | 32964 | 396139 | 0.756  | 0.562 |\n",
      "| bus               | 979   | 16477  | 0.465  | 0.264 |\n",
      "| truck             | 5874  | 129538 | 0.676  | 0.398 |\n",
      "| special vehicle   | 202   | 20152  | 0.163  | 0.018 |\n",
      "| motorcycle        | 235   | 5846   | 0.226  | 0.071 |\n",
      "| bicycle           | 62    | 2004   | 0.194  | 0.033 |\n",
      "| personal mobility | 43    | 5371   | 0.326  | 0.026 |\n",
      "| person            | 7347  | 129396 | 0.615  | 0.362 |\n",
      "| Traffic_light     | 3298  | 25343  | 0.672  | 0.411 |\n",
      "| Traffic_sign      | 2889  | 59831  | 0.751  | 0.589 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "| mAP               |       |        |        | 0.273 |\n",
      "+-------------------+-------+--------+--------+-------+\n",
      "2024-08-15 01:36:16,769 - mmdet - INFO - Epoch(val) [8][10000]\tAP50: 0.2730, mAP: 0.2733\n",
      "2024-08-15 01:47:44,810 - mmdet - INFO - Epoch(val) [8][1000]\tloss_cls: 0.5553, loss_bbox: 0.3236, loss_dfl: 0.2234, loss: 1.1023\n",
      "Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7f046c4a58c0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.7/weakref.py\", line 109, in remove\n",
      "    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_134070/3586079623.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m## 학습 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0mtrain_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/UniverseNet/mmdet/apis/train.py\u001b[0m in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_epochs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                     \u001b[0mepoch_runner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# wait for some hooks like loggers to finish\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/mmcv/runner/epoch_based_runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Prevent possible deadlock during epoch transition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before_train_iter'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build dataset\n",
    "### validation ###\n",
    "val_dataset=copy.deepcopy(cfg.data.val)\n",
    "val_dataset.pipeline=cfg.data.train.pipeline\n",
    "val_ds = build_dataset(val_dataset)\n",
    "### validation  ###\n",
    "\n",
    "\n",
    "## 실제 augmentation 포함 pipeline\n",
    "cfg.train_pipeline = [\n",
    "    # dict(type='LoadImageFromFile'),\n",
    "    # dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(type='Mosaic', img_scale= (320, 480)  , pad_val=114.0),  # crop 과 동일하게 (height, width) 로 되있음\n",
    "    dict(\n",
    "        type='PhotoMetricDistortion',\n",
    "        brightness_delta=32,\n",
    "        contrast_range=(0.5, 1.5),\n",
    "        saturation_range=(0.5, 1.5),\n",
    "        hue_delta=18),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_rgb=True),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='FilterAnnotations', min_gt_bbox_wh=(1, 1), keep_empty=False),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "    \n",
    "]\n",
    "\n",
    "# cfg.data.train.pipeline = cfg.train_pipeline\n",
    "\n",
    "### class imbalance 를 해소하기 위해 oversampling 진행 + mosaic aug\n",
    "### MultiImageMixDataset class를 사용하기 위해서는 load pipeline과 augmentation pipeline을 분리해야 해서 아래와 같이 수정하고 위의 train_pipeline도 수정\n",
    "cfg.data.train = dict(\n",
    "       type='MultiImageMixDataset',\n",
    "                    dataset=dict(\n",
    "                        type='ClassBalancedDataset',\n",
    "                        oversample_thr=0.1,\n",
    "                        dataset=dict(\n",
    "                            type=cfg.dataset_type,\n",
    "                            ann_file='2DBB/training/labels/',\n",
    "                            pipeline=[\n",
    "                                dict(type='LoadImageFromFile'),\n",
    "                                dict(type='LoadAnnotations', with_bbox=True)\n",
    "                            ],\n",
    "                            filter_empty_gt=False)),\n",
    "                     pipeline = cfg.train_pipeline)\n",
    "\n",
    "\n",
    "datasets = [build_dataset(cfg.data.train), val_ds]\n",
    "\n",
    "print(len(datasets[0]))\n",
    "# Build the detector\n",
    "model = build_detector(cfg.model)\n",
    "\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "meta=dict()\n",
    "meta['config'] = cfg.pretty_text\n",
    "meta['seed'] = cfg.seed\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "## 학습 함수 \n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True, meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ec200-a072-410a-bb8a-f3bb59c294df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f2f97-b1d2-4054-82f0-7aa43306c544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a6e478-e295-4e68-a1bf-6bc081ff4892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
