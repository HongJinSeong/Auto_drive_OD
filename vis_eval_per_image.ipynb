{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d5d714a-53ed-40b1-94ca-161505e7a713",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "\n",
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c470d68-b429-40a9-8351-e33d7ba33cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as _glob\n",
    "import pandas as pd\n",
    "import os\n",
    "    \n",
    "def glob(dir, pats, recursive=False):  # faster than match, python3 only\n",
    "    pats = pats if isinstance(pats, (list, tuple)) else [pats]\n",
    "    matches = []\n",
    "    for pat in pats:\n",
    "        matches += _glob.glob(os.path.join(dir, pat), recursive=recursive)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5810a8d7-fa05-40b8-950c-c77ea291f229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### load_annotations에서 뒤의 변수 받는거 custom dataset 에서는 이름을 바꿔도 되지만 아래에\n",
    "#### configuration에서는 무조건 변수명을 ann_file로 받아야함\n",
    "@DATASETS.register_module()\n",
    "class Drive_dataset(CustomDataset):\n",
    "    CLASSES=('car','bus','truck', 'special vehicle', 'motorcycle','bicycle','personal mobility','person','Traffic_light', 'Traffic_sign')\n",
    "\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        \n",
    "        CLASSES_dict = {'car' : 0 , 'bus' : 1, 'truck' : 2, 'special vehicle' : 3, 'motorcycle' : 4,'bicycle' : 5 ,'personal mobility' : 6 \n",
    "                        ,'person' : 7 ,'Traffic_light' : 8, 'Traffic_sign' : 9}\n",
    "        \n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        \n",
    "        data_infos = []\n",
    "        \n",
    "        ls = pd.read_csv(ann_file, header = None)\n",
    "        \n",
    "        for idx,an in enumerate(ls.values):\n",
    "            an=an[0]\n",
    "            json_data = {}\n",
    "            with open(an, \"r\") as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "                \n",
    "            ansplit = an.split('/')\n",
    "            \n",
    "            filename = ansplit[0] + '/' + ansplit[1] + '/' + 'images'+'/'+ json_data['image_name']\n",
    "            \n",
    "            width, height = json_data['image_size']\n",
    "\n",
    "            data_info = dict(filename=filename, width=width, height=height)\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "\n",
    "            for ann_data in json_data['Annotation']:\n",
    "                gt_labels.append(CLASSES_dict[ann_data['class_name']])\n",
    "                gt_bboxes.append(ann_data['data'])\n",
    "\n",
    "\n",
    "            data_anno = dict(\n",
    "                    bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                    labels=np.array(gt_labels, dtype=np.long))\n",
    "\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            \n",
    "            data_infos.append(data_info)\n",
    "            \n",
    "            if idx!=0 and idx%20000==0:\n",
    "                print(str(idx)+'/'+str(len(ls))+' load annotations END!')\n",
    "            \n",
    "        \n",
    "        \n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0861933-640b-44dc-a4e8-189cbc19f572",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 추가수정 기존 받았던 pretrain과 매칭되는 config로 수정 \n",
    "cfg = Config.fromfile('UniverseNet/configs/waymo_open/universenet50_2008_fp16_4x4_mstrain_640_1280_1x_waymo_open_f0.py') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8075517d-ddde-4c9c-afcd-8c712a39841a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "pretrained_ckpt = 'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "model = dict(\n",
      "    type='GFL',\n",
      "    backbone=dict(\n",
      "        type='Res2Net',\n",
      "        depth=50,\n",
      "        scales=4,\n",
      "        base_width=26,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        dcn=dict(type='DCN', deform_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, False, False, True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "        )),\n",
      "    neck=[\n",
      "        dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            start_level=1,\n",
      "            add_extra_convs='on_output',\n",
      "            num_outs=5),\n",
      "        dict(\n",
      "            type='SEPC',\n",
      "            out_channels=256,\n",
      "            stacked_convs=4,\n",
      "            pconv_deform=False,\n",
      "            lcconv_deform=True,\n",
      "            ibn=True,\n",
      "            pnorm_eval=False,\n",
      "            lcnorm_eval=False,\n",
      "            lcconv_padding=1)\n",
      "    ],\n",
      "    bbox_head=dict(\n",
      "        type='GFLSEPCHead',\n",
      "        num_classes=3,\n",
      "        in_channels=256,\n",
      "        stacked_convs=0,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            ratios=[1.0],\n",
      "            octave_base_scale=8,\n",
      "            scales_per_octave=1,\n",
      "            strides=[8, 16, 32, 64, 128]),\n",
      "        loss_cls=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0),\n",
      "        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.25),\n",
      "        reg_max=16,\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=2.0)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(type='ATSSAssigner', topk=9),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.6),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'WaymoOpenDataset'\n",
      "data_root = 'data/waymococo_f0/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(960, 640), (1920, 1280)],\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1248, 832),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_train2020.json',\n",
      "        img_prefix='data/waymococo_f0/train2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(960, 640), (1920, 1280)],\n",
      "                multiscale_mode='range',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_val2020.json',\n",
      "        img_prefix='data/waymococo_f0/val2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1248, 832),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='WaymoOpenDataset',\n",
      "        ann_file='data/waymococo_f0/annotations/instances_val2020.json',\n",
      "        img_prefix='data/waymococo_f0/val2020/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1248, 832),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'https://github.com/shinya7y/UniverseNet/releases/download/20.08/universenet50_2008_fp16_4x4_mstrain_480_960_1x_coco_20200812_epoch_12-f522ede5.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "fp16 = dict(loss_scale=512.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166f454d-8213-4766-820a-bad6e47c3051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 추가 및 수정 ## \n",
    "cfg.dataset_type  = 'Drive_dataset'\n",
    "cfg.data_root = ''\n",
    "\n",
    "## single GPU 이기 때문에 syncBN 이 아닌 BN으로 수정)\n",
    "cfg.model.backbone.norm_cfg=dict(type='BN', requires_grad=True)\n",
    "\n",
    "## Validation pipeline에 train pipeline 적용하기 위해서 구성 \n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='Resize',\n",
    "        img_scale=(1920, 1200),\n",
    "        multiscale_mode='range',\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomFlip', flip_ratio=0.0),\n",
    "    dict(\n",
    "        type='Normalize',\n",
    "        mean=[123.675, 116.28, 103.53],\n",
    "        std=[58.395, 57.12, 57.375],\n",
    "        to_rgb=True),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
    "    \n",
    "]\n",
    "\n",
    "### test pipeline 나중에 test진행에 사용할 거 실제 validation은 위의 pipeline 으로 진행\n",
    "cfg.test_pipeline = [\n",
    "    ### TSET때 사용할 test time augmentation용 pipeline\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "                type='MultiScaleFlipAug',\n",
    "                img_scale=(1920, 1200),\n",
    "                flip=False,\n",
    "                transforms=[\n",
    "                    dict(type='Resize', keep_ratio=True),\n",
    "                    dict(type='RandomFlip'),\n",
    "                    dict(\n",
    "                        type='Normalize',\n",
    "                        mean=[123.675, 116.28, 103.53],\n",
    "                        std=[58.395, 57.12, 57.375],\n",
    "                        to_rgb=True),\n",
    "                    dict(type='Pad', size_divisor=32),\n",
    "                    dict(type='ImageToTensor', keys=['img']),\n",
    "                      dict(type='Collect', keys=['img'])\n",
    "                ])\n",
    "]\n",
    "\n",
    "cfg.data=dict(\n",
    "    samples_per_gpu=10,\n",
    "    workers_per_gpu=12,\n",
    "    train=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        ann_file='2DBB/new_train.csv',\n",
    "        pipeline=cfg.train_pipeline),\n",
    "     val=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        ann_file='2DBB/new_valid.csv',\n",
    "        pipeline=cfg.test_pipeline),\n",
    "    test=dict(\n",
    "        type=cfg.dataset_type,\n",
    "        ann_file='2DBB/new_test.csv',\n",
    "        pipeline=cfg.test_pipeline))\n",
    "\n",
    "cfg.model.bbox_head.num_classes=10\n",
    "\n",
    "cfg.device='cuda'\n",
    "cfg.work_dir = 'checkpoints_ver2'\n",
    "\n",
    "cfg.log_config.interval = 8000 #iteration 단위\n",
    "\n",
    "cfg.seed = 2024\n",
    "\n",
    "set_random_seed(cfg.seed, deterministic=False)\n",
    "\n",
    "cfg.workflow = [('train', 1), ('val',1)]\n",
    "\n",
    "cfg.evaluation = dict(interval=1, metric='mAP')\n",
    "\n",
    "cfg.load_from = 'universenet50_2008_fp16_4x4_mstrain_480_960_2x_coco_20200815_epoch_24-81356447.pth'\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=24)\n",
    "\n",
    "cfg.model.test_cfg['score_thr']=0.05\n",
    "\n",
    "cfg.gpu_ids = range(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "091466f7-6f3b-48c6-a3ea-9eed0dc8897f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "pretrained_ckpt = 'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "model = dict(\n",
      "    type='GFL',\n",
      "    backbone=dict(\n",
      "        type='Res2Net',\n",
      "        depth=50,\n",
      "        scales=4,\n",
      "        base_width=26,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        dcn=dict(type='DCN', deform_groups=1, fallback_on_stride=False),\n",
      "        stage_with_dcn=(False, False, False, True),\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint=\n",
      "            'https://github.com/shinya7y/weights/releases/download/v1.0.2/res2net50_v1b_26w_4s-3cf99910_mmdetv2-92ed3313.pth'\n",
      "        )),\n",
      "    neck=[\n",
      "        dict(\n",
      "            type='FPN',\n",
      "            in_channels=[256, 512, 1024, 2048],\n",
      "            out_channels=256,\n",
      "            start_level=1,\n",
      "            add_extra_convs='on_output',\n",
      "            num_outs=5),\n",
      "        dict(\n",
      "            type='SEPC',\n",
      "            out_channels=256,\n",
      "            stacked_convs=4,\n",
      "            pconv_deform=False,\n",
      "            lcconv_deform=True,\n",
      "            ibn=True,\n",
      "            pnorm_eval=False,\n",
      "            lcnorm_eval=False,\n",
      "            lcconv_padding=1)\n",
      "    ],\n",
      "    bbox_head=dict(\n",
      "        type='GFLSEPCHead',\n",
      "        num_classes=10,\n",
      "        in_channels=256,\n",
      "        stacked_convs=0,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            ratios=[1.0],\n",
      "            octave_base_scale=8,\n",
      "            scales_per_octave=1,\n",
      "            strides=[8, 16, 32, 64, 128]),\n",
      "        loss_cls=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0),\n",
      "        loss_dfl=dict(type='DistributionFocalLoss', loss_weight=0.25),\n",
      "        reg_max=16,\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=2.0)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(type='ATSSAssigner', topk=9),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.6),\n",
      "        max_per_img=100))\n",
      "dataset_type = 'Drive_dataset'\n",
      "data_root = ''\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(1920, 1200),\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.0),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(1920, 1200),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=10,\n",
      "    workers_per_gpu=12,\n",
      "    train=dict(\n",
      "        type='Drive_dataset',\n",
      "        ann_file='2DBB/new_train.csv',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=(1920, 1200),\n",
      "                multiscale_mode='range',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='Drive_dataset',\n",
      "        ann_file='2DBB/new_valid.csv',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1920, 1200),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='Drive_dataset',\n",
      "        ann_file='2DBB/new_test.csv',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1920, 1200),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=24)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=8000, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'universenet50_2008_fp16_4x4_mstrain_480_960_2x_coco_20200815_epoch_24-81356447.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1), ('val', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=False, base_batch_size=16)\n",
      "fp16 = dict(loss_scale=512.0)\n",
      "device = 'cuda'\n",
      "work_dir = 'checkpoints_ver2'\n",
      "seed = 2024\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aada7857-96eb-427e-ada5-cf6037d57c22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c4e807-81d2-4700-a8e7-066fec27745b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/UniverseNet/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "2024-08-06 07:34:59,380 - root - INFO - DeformConv2dPack backbone.layer4.0.convs.0 is upgraded to version 2.\n",
      "2024-08-06 07:34:59,381 - root - INFO - DeformConv2dPack backbone.layer4.0.convs.1 is upgraded to version 2.\n",
      "2024-08-06 07:34:59,382 - root - INFO - DeformConv2dPack backbone.layer4.0.convs.2 is upgraded to version 2.\n",
      "2024-08-06 07:34:59,430 - root - INFO - DeformConv2dPack backbone.layer4.1.convs.0 is upgraded to version 2.\n",
      "2024-08-06 07:34:59,431 - root - INFO - DeformConv2dPack backbone.layer4.1.convs.1 is upgraded to version 2.\n",
      "2024-08-06 07:34:59,431 - root - INFO - DeformConv2dPack backbone.layer4.1.convs.2 is upgraded to version 2.\n",
      "2024-08-06 07:34:59,434 - root - INFO - DeformConv2dPack backbone.layer4.2.convs.0 is upgraded to version 2.\n",
      "2024-08-06 07:34:59,434 - root - INFO - DeformConv2dPack backbone.layer4.2.convs.1 is upgraded to version 2.\n",
      "2024-08-06 07:34:59,435 - root - INFO - DeformConv2dPack backbone.layer4.2.convs.2 is upgraded to version 2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: checkpoints_ver2/epoch_24.pth\n"
     ]
    }
   ],
   "source": [
    "# Build the detector\n",
    "#model = init_detector(config, checkpoint, device='cuda:0')\n",
    "checkpoint='checkpoints_ver2/epoch_24.pth'\n",
    "# model = init_detector(cfg,checkpoint, device='cpu')\n",
    "model = init_detector(cfg, checkpoint, device='cuda:0')\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f4fa2e5-98a1-4b10-abd9-25d23644cfd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls = pd.read_csv('2DBB/new_valid.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff234f26-84aa-4a46-80f0-ee8daf075400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2DBB/training/images/E_DCG_230829_141_FC_127.jpg\n",
      "7\n",
      "2\n",
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "1\n",
      "23\n",
      "12\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import csv\n",
    "csv.register_dialect(\n",
    "    'mydialect',\n",
    "    delimiter = ',',\n",
    "    quotechar = '\"',\n",
    "    doublequote = True,\n",
    "    skipinitialspace = True,\n",
    "    lineterminator = '\\r\\n',\n",
    "    quoting = csv.QUOTE_MINIMAL)\n",
    "\n",
    "def writecsv(csvname,contents):\n",
    "    f = open(csvname, 'a', newline='')\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow(contents)\n",
    "    f.close()\n",
    "    \n",
    "CLASSES=('car','bus','truck', 'special vehicle', 'motorcycle','bicycle','personal mobility','person','Traffic_light', 'Traffic_sign')\n",
    "\n",
    "### iou 계산\n",
    "def iou(box1, box2):\n",
    "  '''Compute the Intersection-Over-Union of two given boxes.\n",
    "  Args:\n",
    "    box1: array of 4 elements [cx, cy, width, height].\n",
    "    box2: same as above\n",
    "  Returns:\n",
    "    iou: a float number in range [0, 1]. iou of the two boxes.\n",
    "  '''\n",
    "\n",
    "  lr = min(box1[0]+0.5*box1[2], box2[0]+0.5*box2[2]) - \\\n",
    "      max(box1[0]-0.5*box1[2], box2[0]-0.5*box2[2])\n",
    "  if lr > 0:\n",
    "    tb = min(box1[1]+0.5*box1[3], box2[1]+0.5*box2[3]) - \\\n",
    "        max(box1[1]-0.5*box1[3], box2[1]-0.5*box2[3])\n",
    "    if tb > 0:\n",
    "      intersection = tb*lr\n",
    "      union = box1[2]*box1[3]+box2[2]*box2[3]-intersection\n",
    "\n",
    "      return intersection/union\n",
    "\n",
    "  return 0\n",
    "\n",
    "### 이미지에 대한 precision recall 측정\n",
    "### 이미지에 대한 iOU 측정이후 threshold 기준으로 class까지 맞으면  TP case count\n",
    "### precision = TP / model로 예측한 이미지별 detection 갯수\n",
    "### recall = TP / 이미지별 Ground truth 갯수\n",
    "### 개별 이미지에 대한 평가를 위해 진행\n",
    "\n",
    "### 메모리 문제 땜시 끊어서... 다시 시작 이후 체크\n",
    "### 773  / 1581\n",
    "\n",
    "for idx,an in enumerate(ls.values):\n",
    "        an=an[0]\n",
    "        json_data = {}\n",
    "        with open(an, \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            \n",
    "        ansplit = an.split('/')\n",
    "\n",
    "        filename = ansplit[0] + '/' + ansplit[1] + '/' + 'images'+'/'+ json_data['image_name']\n",
    "        \n",
    "        GT_COUNT = len(json_data['Annotation']) ## recall 용\n",
    "\n",
    "        output = inference_detector(model, filename)\n",
    "        print(filename)\n",
    "        for oos in output:\n",
    "            print(len(oos))\n",
    "        \n",
    "        DET_COUNT = 0 ## precision 용\n",
    "        TP = 0 \n",
    "#         for i,dets in enumerate(output):\n",
    "#             DET_COUNT += len(dets)\n",
    "            \n",
    "#             for an in json_data['Annotation']:\n",
    "#                 for det in dets:        \n",
    "#                     if an['class_name'] == CLASSES[i]: ### True positive 찾기위해 같은 class 로 예측했을 때만 confidence score는 cfg.model.test_cfg['score_thr']=xxx에서 미리 처리됨\n",
    "                        \n",
    "#                         ## 현재 좌표가 (xmin,ymin,xmax,ymax) 로 되어있어서 iou 함수에 맞게 (x,y,width,height)로 넣어줌\n",
    "#                         val = iou([det[0],det[1],det[2]-det[0],det[3]-det[1]], [an['data'][0],an['data'][1],an['data'][2]-an['data'][0], an['data'][3]-an['data'][1]])\n",
    "                        \n",
    "#                         ## 만약에 1개의 object detection point에 여러개의 True positive가 있으면 1개만 True로 치고 나머지는 틀린것으로 처리\n",
    "#                         ## https://github.com/rafaelpadilla/Object-Detection-Metrics/issues/46 참조\n",
    "                        \n",
    "#                         if val > 0.5:\n",
    "#                             TP += 1\n",
    "#                             break\n",
    "        \n",
    "        # evals['file_nm'].append(filename)\n",
    "        # evals['TP_CNT'].append(TP)\n",
    "        # evals['RECALL'].append(TP/GT_COUNT)\n",
    "        # evals['PRECISION'].append(TP/DET_COUNT)\n",
    "        \n",
    "#         writecsv('vis_ver1/EVAL_PER_IMG.csv', [filename,TP,TP/GT_COUNT,TP/DET_COUNT ])\n",
    "        \n",
    "#         if os.path.isdir('vis_ver1/imgs/'+json_data['image_name'])==False:\n",
    "#             img = cv2.imread(filename)\n",
    "\n",
    "#             out = model.show_result(filename,output,score_thr=0.0)\n",
    "\n",
    "#             concat_img = cv2.hconcat([img, out])\n",
    "#             cv2.imwrite('vis_ver1/imgs/'+json_data['image_name'], concat_img)\n",
    "            \n",
    "#             del img, out, concat_img\n",
    "#         json_file.close()\n",
    "        \n",
    "        break\n",
    "        \n",
    "# df = pd.DataFrame(evals)\n",
    "# df.to_csv('vis_ver1/EVAL_PER_IMG.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22827f8b-39c7-4651-bc4b-db07c5aade7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257a2069-2278-4c5c-8f7d-a38c30ff7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvidi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
